{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_robot(image):\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "    lower_quarter = image[4 * height // 5 :, :] #crop to the lower quarter (to ignore ceiling lights)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(lower_quarter, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Enhance brightness (of the robot light)\n",
    "    bright = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)\n",
    "\n",
    "    # brightness thresholding\n",
    "    brightness_threshold = 40 #TODO better threshold?\n",
    "    _, mask = cv2.threshold(bright, brightness_threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    mask = cv2.bitwise_not(mask) #reversed mask to detect dark\n",
    "\n",
    "\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw contours on the lower half of the image\n",
    "    #cv2.drawContours(lower_half, contours, -1, (0, 255, 0), 2)  # Green contours\n",
    "    #print(len(contours))\n",
    "\n",
    "\n",
    "    # Filter contours by length\n",
    "    robot_detected = False\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w > width // 9:  # Line is larger than 1/4 of the image width at which point we should dodge the robot TODO better strategy?\n",
    "            robot_detected = True\n",
    "            # Show detected line\n",
    "            cv2.rectangle(lower_quarter, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "    # Combine the lower quarter back with the upper half for display\n",
    "    output_image = np.vstack((image[: height // 5 * 4, :], lower_quarter))\n",
    "\n",
    "    return output_image, robot_detected, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_robot(image):\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "    lower_quarter = image[3 * height // 4 :, :] #crop to the lower quarter (to ignore ceiling lights)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(lower_quarter, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Enhance brightness (of the robot light)\n",
    "    bright = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)\n",
    "\n",
    "    # brightness thresholding\n",
    "    brightness_threshold = 40 #TODO better threshold?\n",
    "    _, mask = cv2.threshold(bright, brightness_threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    mask = cv2.bitwise_not(mask) #reversed mask to detect dark\n",
    "\n",
    "\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw contours on the lower half of the image\n",
    "    #cv2.drawContours(lower_half, contours, -1, (0, 255, 0), 2)  # Green contours\n",
    "    #print(len(contours))\n",
    "\n",
    "\n",
    "    # Filter contours by length\n",
    "    robot_detected = False\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w > width // 9:  # Line is larger than 1/4 of the image width at which point we should dodge the robot TODO better strategy?\n",
    "            robot_detected = True\n",
    "            # Show detected line\n",
    "            cv2.rectangle(lower_quarter, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "    # Combine the lower quarter back with the upper half for display\n",
    "    output_image = np.vstack((image[: height // 4 * 3, :], lower_quarter))\n",
    "\n",
    "    return output_image, robot_detected, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot in image:  True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image = cv2.imread('images_obstacle/image_20241125_145857.jpg')\n",
    "image = cv2.imread('images_obstacle/image_20241125_145833.jpg')\n",
    "img_detected, robot_detected, img_mask = detect_robot(image)\n",
    "print('Robot in image: ', robot_detected)\n",
    "\n",
    "cv2.imwrite('processed_image.jpg', img_detected)\n",
    "cv2.imwrite('mask_image.jpg', img_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_obstacle/image_20241125_150017.jpg\n",
      "images_obstacle/image_20241125_150014.jpg\n",
      "images_obstacle/image_20241125_145916.jpg\n",
      "images_obstacle/image_20241125_145926.jpg\n",
      "images_obstacle/image_20241125_150053.jpg\n",
      "images_obstacle/image_20241125_150051.jpg\n",
      "images_obstacle/image_20241125_150055.jpg\n",
      "images_obstacle/image_20241125_145937.jpg\n",
      "images_obstacle/image_20241125_145923.jpg\n",
      "images_obstacle/image_20241125_145857.jpg\n",
      "images_obstacle/image_20241125_145936.jpg\n",
      "images_obstacle/image_20241125_145950.jpg\n",
      "images_obstacle/image_20241125_145833.jpg\n",
      "images_obstacle/image_20241125_145947.jpg\n",
      "images_obstacle/image_20241125_145943.jpg\n",
      "images_obstacle/image_20241125_145942.jpg\n",
      "images_obstacle/image_20241125_150034.jpg\n"
     ]
    }
   ],
   "source": [
    "image_files = glob.glob(\"images_obstacle/*.jpg\")\n",
    "\n",
    "for i, filename in enumerate(image_files):\n",
    "    print(filename)\n",
    "    img = cv2.imread(filename)\n",
    "    img_detected, robot_detected, img_mask = detect_robot(img)\n",
    "\n",
    "    cv2.imwrite(f'{filename}_detection.jpg', img_detected)\n",
    "    cv2.imwrite(f'{filename}_mask.jpg', img_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_robot_blackness(image):\n",
    "    height, width, _ = image.shape\n",
    "    lower_quarter = image[7* height // 8 :, :] #crop to the lower quarter (to ignore ceiling lights)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(lower_quarter, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Enhance brightness (of the robot light)\n",
    "    bright = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)\n",
    "\n",
    "    # brightness thresholding\n",
    "    brightness_threshold = 48 #TODO better threshold?\n",
    "    _, mask = cv2.threshold(bright, brightness_threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "\n",
    "    # proportion black pixels\n",
    "    total_pixels = mask.size  # Total number of pixels\n",
    "    white_pixels = cv2.countNonZero(mask)  # non-zero (black) pixels\n",
    "    #print(mask)\n",
    "    black_pixels = total_pixels-white_pixels\n",
    "    black_proportion = black_pixels / total_pixels\n",
    "    print(black_proportion)\n",
    "\n",
    "    # Determine if the robot is detected\n",
    "    robot_detected = black_proportion > 0.18  # True if more than 18% of the mask is black\n",
    "\n",
    "    # Visualize the result\n",
    "    if robot_detected:\n",
    "        cv2.putText(\n",
    "            lower_quarter,\n",
    "            f\"Robot Detected: {black_proportion*100:.2f}% black\",\n",
    "            (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            (0, 0, 255),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "    # Combine the lower quarter back with the upper part for display\n",
    "    output_image = np.vstack((image[: height // 8 * 7, :], lower_quarter))\n",
    "\n",
    "    return output_image, robot_detected, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1343984375\n",
      "Robot in image:  False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Single image\"\"\"\n",
    "image = cv2.imread('images_obstacle/image_20241125_145937.jpg') #should start to dodge: 150017, 145857, 145916 (extremely close); not: 145937\n",
    "img_detected, robot_detected, img_mask = detect_robot_blackness(image)\n",
    "print('Robot in image: ', robot_detected)\n",
    "\n",
    "cv2.imwrite('processed_image.jpg', img_detected)\n",
    "cv2.imwrite('mask_image.jpg', img_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_obstacle/image_20241125_150017.jpg\n",
      "0.2087734375\n",
      "images_obstacle/image_20241125_150014.jpg\n",
      "0.0832421875\n",
      "images_obstacle/image_20241125_145916.jpg\n",
      "0.2608359375\n",
      "images_obstacle/image_20241125_145926.jpg\n",
      "0.103625\n",
      "images_obstacle/image_20241125_150053.jpg\n",
      "0.0593359375\n",
      "images_obstacle/image_20241125_150051.jpg\n",
      "0.052953125\n",
      "images_obstacle/image_20241125_150055.jpg\n",
      "0.0524375\n",
      "images_obstacle/image_20241125_145937.jpg\n",
      "0.1343984375\n",
      "images_obstacle/image_20241125_145923.jpg\n",
      "0.123015625\n",
      "images_obstacle/image_20241125_145857.jpg\n",
      "0.112796875\n",
      "images_obstacle/image_20241125_145936.jpg\n",
      "0.351171875\n",
      "images_obstacle/image_20241125_145950.jpg\n",
      "0.055625\n",
      "images_obstacle/image_20241125_145833.jpg\n",
      "0.039046875\n",
      "images_obstacle/image_20241125_145947.jpg\n",
      "0.0490625\n",
      "images_obstacle/image_20241125_145943.jpg\n",
      "0.1574609375\n",
      "images_obstacle/image_20241125_150034.jpg\n",
      "0.0175546875\n"
     ]
    }
   ],
   "source": [
    "image_files = glob.glob(\"images_obstacle/*.jpg\")\n",
    "\n",
    "for i, filename in enumerate(image_files):\n",
    "    print(filename)\n",
    "    img = cv2.imread(filename)\n",
    "    img_detected, robot_detected, img_mask = detect_robot_blackness(img)\n",
    "\n",
    "    cv2.imwrite(f'{filename}_detection.jpg', img_detected)\n",
    "    cv2.imwrite(f'{filename}_mask.jpg', img_mask)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ros_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
